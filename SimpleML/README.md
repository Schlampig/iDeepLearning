# Self-trying for machine learning ideas by python.

References:

√ ABRS-SVM:
Tao, D., Tang, X., Li, X., & Wu, X. (2006). Asymmetric bagging and random subspace for support vector machines-based relevance feedback in image retrieval. IEEE transactions on pattern analysis and machine intelligence, 28(7), 1088-1099.

√ CRUS-RF:
Yen, S. J., & Lee, Y. S. (2009). Cluster-based under-sampling approaches for imbalanced data distributions. Expert Systems with Applications, 36(3), 5718-5727.

√ Random Forest:
Breiman, L. (2001). Random forests. Machine learning, 45(1), 5-32.

√ Pattern Discovery:
Chan, T. M., Li, Y., Chiau, C. C., Zhu, J., Jiang, J., & Huo, Y. (2017). Imbalanced target prediction with pattern discovery on clinical data repositories. BMC medical informatics and decision making, 17(1), 47.

√ SMOTE-SVM:
Chawla, N. V., Bowyer, K. W., Hall, L. O., & Kegelmeyer, W. P. (2002). SMOTE: synthetic minority over-sampling technique. Journal of artificial intelligence research, 16, 321-357.

√ SVM：
Vapnik, V. N., & Vapnik, V. (1998). Statistical learning theory (Vol. 1). New York: Wiley.

√ XGBoost:
Chen, T., & Guestrin, C. (2016, August). Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining (pp. 785-794). ACM.

√ LightGBM:
https://github.com/Microsoft/LightGBM
