{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 算法代码使用示例\n",
    "\n",
    "## 以下是ABRS-SVM算法的使用说明，其他算法文件的流程与此相似"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. 载入库，包括三部分：代码处理需要的基本库；数据处理（交叉验证）用到的库；算法及性能评估用到的库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Basic models\n",
    "import traceback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data operation models\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Classifier models\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Evaluation models\n",
    "import sklearn.metrics as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.配置参数\n",
    "#### 其中，origin_pars是一个字典，记录了每种使用参数的名称，及其取值范围。\n",
    "#### 通过sci-kit learn库带的方法ParameterGrid，能生成origin_pars的参数在取值范围内的所有组合形式，存放在pars内\n",
    "#### data_name是数据集名称，k_holdout是外层交叉验证的折数，k_cv是内层交叉验证的折数，pars是参数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Configurations for the model\n",
    "def run_Config():\n",
    "    data_name = 'Thoracic_Surgery_onehot.xlsx'\n",
    "    k_holdout = 5\n",
    "    k_cv = 3\n",
    "    origin_pars = {\n",
    "            'indicator_name': ['macc'],\n",
    "            'ts': [5], # ABRS-SVM_hyper-par\n",
    "            'tf': [5], # ABRS-SVM_hyper-par\n",
    "            'rs': [0.9], # ABRS-SVM_hyper-par\n",
    "            'rf': [0.5,0.7,0.9], # ABRS-SVM_hyper-par\n",
    "            'kernel': ['rbf'],\n",
    "            'C': [0.1,1,10,100],\n",
    "            'gamma': [2,3],\n",
    "            'class_weight':[{1:0.4,2:0.6},{1:0.5,2:0.5}]\n",
    "            }\n",
    "    pars = list(ParameterGrid(origin_pars))\n",
    "    return data_name, k_holdout, k_cv, pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.载入数据集\n",
    "#### run_load_data根据数据集名称，在当前文件夹下读入数据；\n",
    "#### 数据文件默认存储在excel文件中，存在其他文件中的数据需要更改pd.read_excel()方法；\n",
    "#### all_fea是不包含行名与列名的纯数据，一行一个样本，列为特征数，all_label是对应的类别标记；\n",
    "#### get_normal_label()用于将不规则的一个序列按照元素值从小到大的顺序变成规则的序列；\n",
    "#### 例如原始y = [2,5,7,3,4]，变化后为[0,3,4,1,2]；\n",
    "#### 此处使用get_normal_label()规范label的取值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "def run_load_data(data_name):\n",
    "    all = pd.read_excel(data_name)\n",
    "    all = all.values\n",
    "    all_fea = all[:,:-1]\n",
    "    all_label = get_normal_label(all[:,-1])\n",
    "    return all_fea, all_label\n",
    "\n",
    "def get_normal_label(y):\n",
    "    y_uni = np.unique(np.array(y))\n",
    "    for i in xrange(len(y_uni)):\n",
    "        y[np.nonzero(y == y_uni[i])[0]] = i + 1 # i is OK for XGBoost or LGBM, but it must be 'i+1' for the rest methods\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4.内外两层交叉验证\n",
    "#### 外层交叉验证名为HoldoutCV，内层名为GridSearchCV\n",
    "#### HoldoutCV将当前数据集按k_holdout折划分，每一轮内分为learn数据集与test数据集，前者作为数据集带入GridSearchCV训练最优超参数，后者留出来作为测试数据；\n",
    "#### GridSearchCV将learn数据集进一步划分为train与validation样本，每一轮使用train样本训练模型，再用validation样本测试模型性能；\n",
    "#### GridSearchCV只记录下表现最佳的模型（即，模型的超参数组合）；\n",
    "#### pars里的每组参数都需要在GridSearchCV内验证得到结果，但只有具有最佳超参数组合的模型能带入后续测试环节；\n",
    "#### run_ABRSSVM()是算法ABRS-SVM的实现方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Run both HoldoutCV and GridSearchCV\n",
    "def run_doubleCV(all_fea, all_label, k_holdout, k_cv, pars):\n",
    "    # HoldoutCV\n",
    "    i_t = 0\n",
    "    res_list = []\n",
    "    opt_pars_list = []\n",
    "    holdoutcv = StratifiedKFold(n_splits = k_holdout, shuffle = True)\n",
    "    for i_learn, i_test in holdoutcv.split(all_fea, all_label):\n",
    "        # Times\n",
    "        i_t = i_t + 1\n",
    "        # print 'Round ', str(i_t), ' Holdout CV----------------------'\n",
    "        \n",
    "        # Obtain current learning and heldout data\n",
    "        learn_fea, test_fea = all_fea[i_learn], all_fea[i_test]\n",
    "        learn_label, test_label = all_label[i_learn], all_label[i_test]\n",
    "        \n",
    "        # GridSearchCV\n",
    "        j_t = 0\n",
    "        optdata = {'score':0}\n",
    "        for i_pars in pars:\n",
    "            # times\n",
    "            j_t = j_t + 1\n",
    "            # print 'round ', str(j_t), ' gridsearch cv----------------'\n",
    "            pars_score = []\n",
    "            gridcv = StratifiedKFold(n_splits = k_cv, shuffle = True)\n",
    "            for i_train, i_valid in gridcv.split(learn_fea, learn_label):\n",
    "                # obtain current training and validation data\n",
    "                train_fea, valid_fea = learn_fea[i_train], learn_fea[i_valid]\n",
    "                train_label, valid_label = learn_label[i_train], learn_label[i_valid]\n",
    "                # learn the model\n",
    "                # i_pars = {'par_name1':par1,'par_name2':par2,...,'par_nameN':parN}\n",
    "                valid_pre, pars_new = run_ABRSSVM(i_pars, train_fea, train_label, valid_fea)\n",
    "                grid_score = run_validation(valid_pre, valid_label, i_pars['indicator_name'])\n",
    "                pars_score.append(grid_score)\n",
    "            if np.mean(pars_score) > optdata['score']:\n",
    "                optdata['pars'] = pars_new\n",
    "                optdata['score'] = np.mean(pars_score)\n",
    "                    \n",
    "        # Holdout testing\n",
    "        # best_pars is a dict too\n",
    "        best_pars = optdata['pars']\n",
    "        test_pre, _ = run_ABRSSVM(best_pars, learn_fea, learn_label, test_fea)\n",
    "        \n",
    "        # Evaluate the prediction\n",
    "        res_now = run_evaluation(test_pre, test_label)\n",
    "        \n",
    "        # Save results\n",
    "        res_list.append(res_now)\n",
    "        opt_pars_list.append(best_pars)\n",
    "        \n",
    "    return res_list, opt_pars_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 5. ABRS-SVM算法实现\n",
    "#### run_ABRSSVM()是算法ABRS-SVM的实现方法。\n",
    "#### 输入参数包括：参数组合p，数据矩阵X（用于训练），X的类别标记向量y，数据矩阵Z（用于测试或验证）\n",
    "#### 该方法首先在原数据矩阵上分开正负类样本，接着在特征与样本层面都进行随机下采样，由每个下采样样本训练基分类器（此代码中是SVM），最后由基分类器投票预测Z里面的样本类别标记。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Run ABRS-SVM\n",
    "def run_ABRSSVM(p, X, y, Z):\n",
    "    \n",
    "    # split postive and negative data\n",
    "    X_pos, y_pos, X_neg, y_neg = get_imbalance_split(X, y)\n",
    "    n_pos_s = X_pos.shape[0]\n",
    "    n_neg_s, n_neg_f = X_neg.shape\n",
    "    \n",
    "    # initialize hyper-parameters\n",
    "    ts, tf, rf = p['ts'], p['tf'], p['rf']\n",
    "    if p.has_key('rs'):\n",
    "        rs = p['rs']\n",
    "    else:\n",
    "        if n_pos == 0:\n",
    "            raise Exception(\"No positive samples!\")\n",
    "        else:\n",
    "            rs = n_pos_s/float(n_neg_s)\n",
    "        \n",
    "    # generate sub-sampling slice for both samples and features\n",
    "    slice_s, slice_f = get_slice(ts, tf, n_neg_s, n_neg_f, rs, rf)\n",
    "    \n",
    "    # train base learners\n",
    "    svmclf = []\n",
    "    for i in slice_s:\n",
    "        for j in slice_f:\n",
    "            # generate the currently used dataset\n",
    "            X_now = np.concatenate((X_pos[:, j], X_neg[i,:][:,j]), axis = 0)\n",
    "            y_now = np.concatenate((y_pos, y_neg[i]), axis = 0)\n",
    "            i_shuffle = np.random.permutation(len(y_now))\n",
    "            X_now = X_now[i_shuffle, :] \n",
    "            y_now = y_now[i_shuffle] \n",
    "            # train the classifier\n",
    "            clf = SVC(C=p['C'], kernel=p['kernel'], gamma=p['gamma'], class_weight=p['class_weight'])\n",
    "            clf.fit(X_now, y_now)\n",
    "            svmclf.append(clf)\n",
    "            \n",
    "    # testing\n",
    "    vote_mat = []\n",
    "    for c in svmclf:\n",
    "        vote_now = c.predict(Z[:, j])\n",
    "        vote_mat.append(vote_now)\n",
    "        \n",
    "    # voting\n",
    "    zpre = get_vote(vote_mat)\n",
    "    \n",
    "    return zpre, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 6.不平衡数据集判断及划分\n",
    "#### 一些不平衡方法由于涉及采样与加权，当正类数目大于负类数目时可能出错，因此需要一个方法来纠正样本数目\n",
    "#### get_imbalance_split()方法用于纠正两类样本数目，总是把样本上数更多的一方设为负类。且当类别数大于2就报错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_imbalance_split(X, y):\n",
    "    v = np.unique(y)\n",
    "    if len(v) == 2:\n",
    "        if sum(y == v[0]) >= sum(y == v[1]):\n",
    "            X_pos = X[y == v[1],:]\n",
    "            X_neg = X[y == v[0],:]\n",
    "            y_pos = y[y == v[1]]\n",
    "            y_neg = y[y == v[0]]\n",
    "        else:\n",
    "            X_pos = X[y == v[0],:]\n",
    "            X_neg = X[y == v[1],:]\n",
    "            y_pos = y[y == v[0]]\n",
    "            y_neg = y[y == v[1]]\n",
    "    else:\n",
    "        raise Exception(\"Not a binary-class!\")    \n",
    "        \n",
    "    return X_pos, y_pos, X_neg, y_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 7. 切片（提取采样的下标）\n",
    "#### get_slice()是run_ABRSSVM()方法中的一步，用于下采样样本及特征。\n",
    "#### ts是采集的样本的次数，tf是采集的特征的次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_slice(ts, tf, ns, nf, rs, rf):\n",
    "    # Function to generate slices of the undersampling samples and features\n",
    "    # ts, tf: number of batches for sub-sample and sub-feature\n",
    "    # ns, nf: number of original (negative) samples and features\n",
    "    # rs, rf: ratio of undersampling samples and features\n",
    "    import random\n",
    "    \n",
    "    sub_s = int(ns*rs)\n",
    "    sub_f = int(nf*rf)\n",
    "    slice_s = []\n",
    "    slice_f = []\n",
    "    for i in xrange(ts):\n",
    "        for j in xrange(tf):\n",
    "            now_s = range(ns)\n",
    "            random.shuffle (now_s)\n",
    "            slice_s.append(now_s[:sub_s])\n",
    "            now_f = range(nf)\n",
    "            random.shuffle (now_f)\n",
    "            slice_f.append(now_f[:sub_f])\n",
    "    return slice_s, slice_f                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 8.投票\n",
    "#### 当ABRS-SVM进入测试环节，不是像bagging那样简单aggregate样本，而是使用投票机制。\n",
    "#### 每个基分类器对当前测试样本给出一个预测，相同预测值最高的预测将作为最终预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_vote(V):\n",
    "    N = len(V[0]) # number of samples\n",
    "    C = len(np.unique(V)) # number of classes\n",
    "    zpre = []\n",
    "    for i in xrange(N):\n",
    "        sample_now = [v[i] for v in V]\n",
    "        pre_now = max(sample_now, key = sample_now.count)\n",
    "        zpre.append(pre_now)   \n",
    "    return np.array(zpre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 9. 验证\n",
    "#### run_validation()方法用于验证预测类别标记向量zpre和真实标记向量z之间的差异；\n",
    "### s_name是用于选择使用哪种验证方法的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Obtain the score\n",
    "def run_validation(zpre, z, s_name):\n",
    "    i_pos = np.nonzero(z == max(z))\n",
    "    i_neg = np.nonzero(z == min(z))\n",
    "    tpr = (1 - sm.hamming_loss(z[i_pos], zpre[i_pos]))*100\n",
    "    tnr = (1 - sm.hamming_loss(z[i_neg], zpre[i_neg]))*100\n",
    "    if s_name.lower() == 'macc':\n",
    "        s = 0.5*(tpr+tnr)\n",
    "    elif s_name.lower() == 'gm':\n",
    "        s = np.sqrt(tpr*tnr)\n",
    "    elif s_name.lower() == 'tpr':\n",
    "        s = tpr\n",
    "    else: # error\n",
    "        s = sum((1 if i_pre == i_true else 0 for i_pre, i_true in zip(zpre,z)))/float(len(z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 10.性能评估\n",
    "#### 采用了以下评估指标：True Positive Rate (TPR), True Negative Rate (TNR),\n",
    "#### MAcc = 0.5*(TPR+TNR), GM = sqrt(TPR*TNR),\n",
    "#### F1(macro & micro)\n",
    "#### Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the performance\n",
    "def run_evaluation(p, y):\n",
    "    res_dict = {}\n",
    "    i_pos = np.nonzero(y == max(y))\n",
    "    i_neg = np.nonzero(y == min(y))\n",
    "    res_dict['TPR'] = (1 - sm.hamming_loss(y[i_pos], p[i_pos]))*100\n",
    "    res_dict['TNR'] = (1 - sm.hamming_loss(y[i_neg], p[i_neg]))*100\n",
    "    res_dict['MAcc'] = np.mean([res_dict['TPR'], res_dict['TNR']])\n",
    "    res_dict['GM'] = np.sqrt(res_dict['TPR']*res_dict['TNR'])\n",
    "    res_dict['F1(Macro)'] = sm.f1_score(y, p, average='macro')*100\n",
    "    res_dict['F1(Micro)'] = sm.f1_score(y, p, average='micro')*100\n",
    "    res_dict['Acc'] = sm.accuracy_score(y, p)*100\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 11. 用于显示出生成的最嫁分类结果背后对应的超参数组合，以及最优分类结果是多少。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_dict(d):\n",
    "    list_final = []\n",
    "    for i in d:\n",
    "        list_now = i + '_' + str(d[i])\n",
    "        list_final.append(list_now)\n",
    "    return list_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 12. 调用01-11方法的主方法。\n",
    "#### 首先调用配置参数的方法。\n",
    "#### 接着载入数据集。\n",
    "#### 之后调用交叉验证方法，并得到结果。\n",
    "#### 最后打印字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    data_name, k_holdout, k_cv, pars = run_Config()\n",
    "    all_fea, all_label = run_load_data(data_name)\n",
    "    res_list, opt_pars_list = run_doubleCV(all_fea, all_label, k_holdout, k_cv, pars)\n",
    "    #print 'Each heldout cv result:'\n",
    "    #print '-----------------------'\n",
    "    for i, j in zip(res_list,opt_pars_list):\n",
    "        print get_dict(i), 'with hyper-parameters:'\n",
    "        print get_dict(j)\n",
    "        print '-----------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
